{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"welcome to my digital lab notebook","text":""},{"location":"#about-me","title":"about me","text":"<p>I'm an entrepreneur-engineer, researcher, engineer, technologist, musician, and linguaphile. </p> <p>I am co-founder and CTO at Olibra (Bond Home), where I lead a team building next-generation user experiences for smart home.</p> <p>My primary research interest at this time is AI interpretability, specifically how character-level language models learn morphemes and their meanings.</p> <p>Otherwise I spend my time covering sad girl music, taking friends foraging, ever so gradually learning Latin, and teaching kids to solder and code.</p>"},{"location":"#latest-research-notes","title":"Latest research notes","text":"<ul> <li>Research Overview</li> </ul> <p>Feel free to reach out on GitHub if you have any questions or suggestions! </p>"},{"location":"research/","title":"Research Notes Overview","text":"<p>This section collects informal research experiments, prototypes, and thought pieces.</p> <p>\"Research is what I'm doing when I don't know what I'm doing.\" \u2014 Wernher von Braun</p> <p>Expect messy code, half-baked ideas, and plenty of TODOs. </p> \\[ P(W) = \\prod_{i=1}^n P(w_i | w_1, w_2, ..., w_{i-1}) \\] <pre><code>import numpy as np\nfrom tinygrad.tensor import Tensor\n\n# Create a tinygrad tensor\nx = Tensor([1.0, 2.0, 3.0], requires_grad=True)\n</code></pre>"}]}